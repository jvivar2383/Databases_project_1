{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fa7a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sk/km6c1g654036cmvl40zycd0m0000gn/T/ipykernel_3321/1892829989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "import selenium.webdriver as webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "import re\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge mysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503484f-a188-480e-b228-cce4f093d167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad515726-2c67-4ee8-9837-5892ccae9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function determined if the url enter is accurate\n",
    "def get_source(url):\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part gets all anchors in the website. The scraper will avoid Google ads and all unwanted Google links\n",
    "def scrape_google(query):\n",
    "\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = get_source(\"https://www.google.com/search?q=\" + query)\n",
    "\n",
    "    links = list(response.html.absolute_links)\n",
    "    google_domains = ('https://www.google.', \n",
    "                      'https://google.', \n",
    "                      'https://webcache.googleusercontent.', \n",
    "                      'http://webcache.googleusercontent.', \n",
    "                      'https://policies.google.',\n",
    "                      'https://support.google.',\n",
    "                      'https://www.googleadservices.'\n",
    "                      'https://maps.google.')\n",
    "\n",
    "    for url in links[:]:\n",
    "        if url.startswith(google_domains):\n",
    "            links.remove(url)\n",
    "   \n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aadbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searchers to seek\n",
    "plants_search = ['house plants', 'green plants', 'plants','hard to kill plants', 'low light plants', \\\n",
    "              'how to take care of plants', 'cacti', 'easy plants', 'outdoor plants', 'winter plants',\\\n",
    "             'summer plants', 'all year round plants', 'flowering plants', 'wall plants', \\\n",
    "                 'green plants', 'easy house plants', 'easy to care plants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending each outcome list into a list\n",
    "results = []\n",
    "for query in plants_search:\n",
    "    result = scrape_google(query)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e140d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of nested list into a 1D list\n",
    "flat_list = []\n",
    "for lst in results:\n",
    "    for element in lst:\n",
    "        flat_list.append(element)\n",
    "print(len(flat_list))\n",
    "print(len(set(flat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc103e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e94d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diandra's code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "from my_fake_useragent import UserAgent\n",
    "import requests\n",
    "import re\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ua = UserAgent()\n",
    "query=\"plants\"\n",
    "number_result=100\n",
    "google_url = \"https://google.com/search?q=\" + query + \"&num=\" + str(number_result)\n",
    "response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "\n",
    "links = []\n",
    "titles = []\n",
    "descriptions = []\n",
    "for r in result_div:\n",
    "    # Checks if each element is present, else, raise exception\n",
    "    try:\n",
    "        link = r.find('a', href = True)\n",
    "        title = r.find('div', attrs={'class':'vvjwJb'}).get_text()\n",
    "        description = r.find('div', attrs={'class':'s3v9rd'}).get_text()\n",
    "        \n",
    "        # Check to make sure everything is present before appending\n",
    "        if link != '' and title != '' and description != '': \n",
    "            links.append(link['href'])\n",
    "            titles.append(title)\n",
    "            descriptions.append(description)\n",
    "    # Next loop if one element is not present\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(len(links))\n",
    "cleaned_urls = []\n",
    "for url in links:\n",
    "    clean_url = url.strip('/url?q =')\n",
    "    cleaned_urls.append(clean_url)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adele's code\n",
    "\n",
    "import urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from my_fake_useragent import UserAgent\n",
    "#from requests_html import HTMl\n",
    "#from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Search_item = \"plants\"\n",
    "number_result =100\n",
    "User_Agent = {\n",
    "        'User-Agent': \n",
    "  \"args\" , \n",
    "  \"headers\": {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "    \"Accept-Language\": \"en-us\", \n",
    "    \"Host\": \"httpbin.org\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.3 Safari/605.1.15\", \n",
    "    \"X-Amzn-Trace-Id\": \"Root=1-62380878-37f2ea371f802f5972280aae\"\n",
    "  }, \n",
    "  \"origin\": \"158.222.133.218\", \n",
    "  \"url\": \"https://httpbin.org/get\"\n",
    "}\n",
    "    \n",
    "bing_url = \"https://www.bing.com/search?q=\" + Search_item + \"&number_result\" + str(number_result)\n",
    "response= requests.get(bing_url, {User_Agent : User_Agent})\n",
    "soup = Beautifulsoup(response.text, \"html.parser\")\n",
    "result_div = soup.find_all('div', attrs = {'class' : 'ZINbbc'})\n",
    "\n",
    "links = []\n",
    "titles = []\n",
    "descriptions = []\n",
    "for r in result_div:\n",
    "    try:\n",
    "        link = r.find('a' , href = True)\n",
    "        title = r.find('dive', attrs = {'class':'vvjwb'}).get_text()\n",
    "        description= r.find('dive', attrs = {'class':'a3v9rd'}).get_text()\n",
    "         \n",
    "        if link != '' and title != '' and description != '':\n",
    "            links.append(link['href'])\n",
    "            titles.append(link['href'])\n",
    "            descriptions.eppend(description)\n",
    "    except:\n",
    "         continue\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc108af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oxana's code\n",
    "def get_source(url):\n",
    "    \"\"\"Return the source code for the provided URL. \n",
    "\n",
    "    Args: \n",
    "        url (string): URL of the page to scrape.\n",
    "\n",
    "    Returns:\n",
    "        response (object): HTTP response object from requests_html. \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "def get_results(query):\n",
    "    \n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = get_source(\"https://search.yahoo.com/search?p=\" + query)\n",
    "    \n",
    "    return response\n",
    "def scrape_yahoo(query):\n",
    "\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = get_source(\"https://search.yahoo.com/search?p=\" + query)\n",
    "\n",
    "    links = list(response.html.absolute_links)\n",
    "    yahoo_domains = ('https://www.yahoo.', \n",
    "                      'https://yahoo.', \n",
    "                      'https://webcache.yahoo.', \n",
    "                      'http://webcache.yahoo.', \n",
    "                      'https://policies.yahoo.',\n",
    "                      'https://support.yahoo.',\n",
    "                      'https://maps.yahoo.')\n",
    "\n",
    "    for url in links[:]:\n",
    "        if url.startswith(yahoo_domains):\n",
    "            links.remove(url)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a5dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flower_plants=['flower plants']\n",
    "results_1 = []\n",
    "for query in flower_plants:\n",
    "    result = scrape_yahoo(query)\n",
    "    results_1.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list_1 = []\n",
    "for lst in results_1:\n",
    "    for element in lst:\n",
    "        flat_list_1.append(element)\n",
    "print(len(flat_list_1))\n",
    "print(len(set(flat_list_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5392ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls= flat_list+ cleaned_urls + flat_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = set(all_urls)\n",
    "all_urls = list(all_)\n",
    "print(len(all_urls))\n",
    "print(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding values to the database\n",
    "try:\n",
    "    connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='MY_CUSTOM_BOT',\n",
    "                                         user='root',\n",
    "                                         password='Soyunaloca1')\n",
    "    if connection.is_connected():\n",
    "        db_Info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_Info)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        \n",
    "        sql = \"INSERT INTO url_table (id_, link) VALUES (%s, %s)\"\n",
    "        \n",
    "        for i in range(0,len(all_urls)):\n",
    "            \n",
    "            cursor.execute(sql, (i, all_urls[i]))\n",
    "            connection.commit()\n",
    "            #cursor.commit() \n",
    "            \n",
    "            \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "    \n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f7ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed0493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
